---
title: "Overview of All Packages"
description: The future framework with the future package at the code comprises many packages - use the ones that suits your needs
preview: images/site_preview.png
format: html
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

### The core package

* **[future]** - _Unified Parallel and Distributed Processing in R for Everyone_<br>
This is the core package of the future framework.  It implements the Future API, which comprises three basic functions - `future()`, `resolved()`, and `value()`, is designed to unify parallel processing in R at the lowest possible level. It provides a standard for building richer, higher-level parallel frontends without having to worry about and re-implement common, critical tasks such as identifying global variables and packages, parallel RNG, and relaying of output and conditions - cumbersome tasks that are often essential to parallel processing.
Nearly all parallel processing tasks can be implemented using this low-level API. But, most users and package developers use the futures via higher-level map-reduce functions provided by **future.apply**, **furrr**, and **foreach** with **doFuture**.


### Parallel map-reduce functions for popular programming style

* **[future.apply]** - _Apply Function to Elements in Parallel using Future_<br>
Implementations of `apply()`, `by()`, `eapply()`, `lapply()`, `Map()`, `.mapply()`, `mapply()`, `replicate()`, `sapply()`, `tapply()`, and `vapply()` that can be resolved using any future-supported backend, e.g. parallel on the local machine or distributed on a compute cluster. These `future_*apply()` functions come with the same pros and cons as the corresponding **base R** `*apply()` functions but with the additional feature of being able to be processed via the future framework.

* **[furrr]** - _Apply Mapping Functions in Parallel using Futures_<br>
Implementations of the family of `map()` functions from **purrr** that can be resolved using any **future**-supported backend, e.g. parallel on the local machine or distributed on a compute cluster. (Developed by Davis Vaughan)

* **foreach** with **[doFuture]** - _Use Foreach to Parallelize via the Future Framework_<br>
The **doFuture** package combines the best of **foreach** and **future** and offers two alternative solution: (i) the traditional `foreach(...) %dopar% { ... }` solution together via `registerDoFuture()`, and (ii) the modern `foreach(...) %dofuture% { ... }` by itself.

* **BiocParallel** with **[BiocParallel.FutureParam]** - _Use Futures with BiocParallel_<br>
A 'BiocParallelParam' class for using futures with the **BiocParallel** framework, e.g. `BiocParallel::register(FutureParam())`.   An alternative, is to use `BiocParallel::register(DoParam())` in combination of **doFuture**.


### Choosing how and where to parallelize

* **[future]** - the **future** package has a set of built-in parallel backends that build upon the **parallel** package, e.g. `multicore`, `multisession`, and `cluster`.

* **[future.batchtools]** - _A Future API for Parallel and Distributed Processing using batchtools_<br>
Implementation of the Future API on top of the **batchtools** package. This allows you to process futures, as defined by the **future** package, in parallel out of the box, not only on your local machine or ad-hoc cluster of machines, but also via high-performance compute (HPC) job schedulers such as LSF, OpenLava, Slurm, SGE, and TORQUE/PBS, e.g. `y <- future.apply::future_lapply(files, FUN = process)`.

* **[future.callr]** - _A Future API for Parallel Processing using callr_<br>
Implementation of the Future API on top of the **callr** package. This allows you to process futures, as defined by the **future** package, in parallel out of the box, on your local (Linux, macOS, Windows, ...) machine. Contrary to backends relying on the **parallel** package (e.g. `future::multisession`), the `callr` backend provided here can run more than 125 parallel R processes.

* **[future.mirai]** - _A Future API for Parallel Processing using mirai_<br>
Implementation of the Future API on top of the **mirai** package. This allows you to process futures, as defined by the **future** package, in parallel out of the box, on local and remote machines. The **mirai** package implements distributed computing via local or network resources and supports Transport Layer Security over TCP/IP for remote connections.


### Reporting on progress

* **[progressr]** - _An Inclusive, Unifying API for Progress Updates_<br>A
 minimal, unifying API for scripts and packages to report progress updates from anywhere including when using parallel processing. The package is designed such that the developer can to focus on what progress should be reported on without having to worry about how to present it. The end user has full control of how, where, and when to render these progress updates, including via progress bars of the popular **progress** package.
The future ecosystem support **progressr** at its core and many of the backends can report progress in a near-live fashion.

### Validation

* **[future.tests]** - _Test Suite for Future API Backends_<br>
Backends implementing the Future API, as defined by the **future** package, should use the tests provided by this package to validate that they meet the minimal requirements of the Future API. The tests can be performed easily from within R or from outside of R from the command line making it easy to include them package tests and in Continuous Integration (CI) pipelines.


### Supporting packages

* **[parallelly]** - _Enhancing the parallel Package_<br>
Utility functions that enhance the **parallel** package and support the built-in parallel backends of the **future** package.

* **[globals]** - _Identify Global Objects in R Expressions_<br>
Identifies global ("unknown" or "free") objects in R expressions by code inspection using various strategies (ordered, liberal, or conservative). The objective of this package is to make it as simple as possible to identify global objects for the purpose of exporting them in parallel, distributed compute environments.

* **[listenv]** - _Environments Behaving (Almost) as Lists_<br>
List environments are environments that have list-like properties. For instance, the elements of a list environment are ordered and can be accessed and iterated over using index subsetting, e.g. `x <- listenv(a = 1, b = 2);` `for (i in seq_along(x)) x[[i]] <- x[[i]] ^ 2;` `y <- as.list(x)`.

* **[marshal]** - _Framework to Marshal Objects to be Used in Another R Process_<br>
_PROTOTYPE_: Some types of R objects can be used only in the R session they were created. If used as-is in another R process, such objects often result in an immediate error or in obscure and hard-to-troubleshoot outcomes. Because of this, they cannot be saved to file and re-used at a later time. They can also not be exported to a worker in parallel processing. These objects are sometimes referred to as non-exportable or non-serializable objects. One solution to this problem is to use “marshaling” to encode the R object into an exportable representation that then can be used to re-create a copy of that object in another R process.




[future]: https://future.futureverse.org
[future.apply]: https://future.apply.futureverse.org
[furrr]: https://furrr.futureverse.org/
[doFuture]: https://doFuture.futureverse.org
[BiocParallel.FutureParam]: https://BiocParallel.FutureParam.futureverse.org
[future]: https://future.futureverse.org
[future.batchtools]: https://future.batchtools.futureverse.org
[future.callr]: https://future.callr.futureverse.org
[future.mirai]: https://future.mirai.futureverse.org
[progressr]: https://progressr.futureverse.org
[future.tests]: https://future.tests.futureverse.org
[parallelly]: https://parallelly.futureverse.org
[marshal]: https://marshal.futureverse.org
[globals]: https://globals.futureverse.org
[listenv]: https://listenv.futureverse.org
